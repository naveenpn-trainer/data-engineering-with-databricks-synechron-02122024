# Exploring Spark SQL

> Spark SQL is one of the module in the Spark ecosystem to query and analyze structured and semi-structured data

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfNdIs3l_Qb-v5QfOhAPWSeiBFZh5yTnoXQGvCW1hn9h2oKcfAzHbtjtWnYWE2rO437ZKKfqzvQBhHwnnEbsajd-2_206jX0BuFKAvgFK1A9UiLVTgBR4uPsGQv-QksjRIvfX5SRiY93OJYqyL8AbRnDXQ?key=yGW25KMloT80Lch6YWjT9A)

In any spark application you perform three steps

1. Load the data
2. Process the data
3. Write the result to different destination

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXc6TVd4PtMfrjyZFb_gth1XcOTUyDFM-9QS-H3SoqlWm1iRv3LEfCachU3bLZjrYV8gw5e1WH2GD6zhKn15_C4BGtd8NANGSV0aggVaB_z7Kk-WFb_ac3hnXIv1JHFsv12JdI9Iz69LFYtIO6Bl-pHf-YNK?key=yGW25KMloT80Lch6YWjT9A)

**Important Points**

* All the methods to create DF is present inside DataFrameReader

  ```
  dfr = spark.read
  ```

* Once a DataFrameReader objects

  * .csv

  * .json

  * .paraquet

  * .jdbc

  * .load

  * .orc

    ```
    user_df = dfr.csv(path="path")
    ```



```
dfr = spark.read
df = dfr.csv(path="")


df = spark.read.csv(path="")
```

## What is Spark DataFrame

> A DataFrame is a distributed collection of data organized into named columns

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcoBTWVRxQsd0EwrurDS_DmfTdW5CEuIxyg98r10dW3DHutgVCa_U_Wbi7jh3OyYnh3l7oJnuORAn0PhWsD__NqI6qzhlL3YG5GdGQWAGD0hL8jjxfDnB2yPjV4h-k3v5b2bKymGVRL0M-0fo0rOfMC298g?key=yGW25KMloT80Lch6YWjT9A)

